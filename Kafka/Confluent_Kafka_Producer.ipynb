{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_cv9Vio1kwMe"
      },
      "outputs": [],
      "source": [
        "# Send message to confluent Kafka topic via python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Required connection configs for Kafka producer, consumer, and admin\n",
        "bootstrap.servers=pkc-619z3.us-east1.gcp.confluent.cloud:9092\n",
        "security.protocol=SASL_SSL\n",
        "sasl.mechanisms=PLAIN\n",
        "sasl.username=7K4SVPMLQXL5AL3A\n",
        "sasl.password=5XTw3jiNzKiLQLmv0nAmqbQvwgQS/BKD1yF9NchOWAZrj6NrPtMsz5LoZ7DPZ9Vt\n",
        "\n",
        "# Best practice for higher availability in librdkafka clients prior to 1.7\n",
        "session.timeout.ms=45000\n",
        "\n",
        "client.id=ccloud-python-client-b18b45dd-cd5b-4861-83c8-efe5f5b48977"
      ],
      "metadata": {
        "id": "990KjmIJlRAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install confluent-kafka"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJ1kZ93mk5OC",
        "outputId": "da7fcb9e-bfad-43f5-fcb4-cfdc9b23caec"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting confluent-kafka\n",
            "  Downloading confluent_kafka-2.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (22 kB)\n",
            "Downloading confluent_kafka-2.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (3.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: confluent-kafka\n",
            "Successfully installed confluent-kafka-2.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from confluent_kafka import Producer\n",
        "import json\n",
        "import time\n",
        "import pandas as pd\n",
        "\n"
      ],
      "metadata": {
        "id": "FZXP0s-2k5SI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/data_test_kafka/first_100_rows.csv')\n",
        "df.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "anq0NbwNk5U0",
        "outputId": "28a1c932-429f-47a4-ec26-966dd0d59168"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "customer_id          99\n",
              "name                 99\n",
              "city                 99\n",
              "state                99\n",
              "country              99\n",
              "registration_date    99\n",
              "is_active            99\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>customer_id</th>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>name</th>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>city</th>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>state</th>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>country</th>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>registration_date</th>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>is_active</th>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "json_output = df.to_dict(orient='records')\n",
        "\n",
        "json_file = 'customer.json'\n",
        "\n",
        "with open(json_file,'w') as f:\n",
        "  json.dump(json_output,f,indent=4)\n",
        "\n",
        "print('Data converted to json and save in customer.json')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHupx2_8k5XD",
        "outputId": "9425a996-d458-44d5-e4b2-9b4c9f502376"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data converted to json and save in customer.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# code to extract first 100 records from the big csv: (Ignore)"
      ],
      "metadata": {
        "id": "F2uJ0agvoNum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "import csv\n",
        "\n",
        "def extract_and_save_first_n_rows(input_csv_filepath, output_csv_filepath, n=100):\n",
        "    \"\"\"Extracts the first n rows from an input CSV and saves them to a new CSV.\n",
        "\n",
        "    Args:\n",
        "        input_csv_filepath (str): The path to the input CSV file.\n",
        "        output_csv_filepath (str): The path to the output CSV file.\n",
        "        n (int, optional): The number of rows to extract. Defaults to 100.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(input_csv_filepath, 'r', newline='') as infile, \\\n",
        "             open(output_csv_filepath, 'w', newline='') as outfile:\n",
        "            reader = csv.reader(infile)\n",
        "            writer = csv.writer(outfile)\n",
        "            for i, row in enumerate(reader):\n",
        "                if i < n:\n",
        "                    writer.writerow(row)\n",
        "                else:\n",
        "                    break\n",
        "        print(f\"Successfully extracted the first {n} rows and saved to {output_csv_filepath}\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Input file not found at {input_csv_filepath}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "# Example usage:\n",
        "input_file = '/content/data_test_kafka/customers.csv'  # Replace with the actual path to your input CSV file\n",
        "output_file = '/content/data_test_kafka/first_100_rows.csv'  # Replace with the desired path for the output CSV file\n",
        "extract_and_save_first_n_rows(input_file, output_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "AsIrTiYqbCvT",
        "outputId": "4770b9e9-ad22-41f2-b482-6bbf0ccfbc78"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully extracted the first 100 rows and saved to /content/data_test_kafka/first_100_rows.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from confluent_kafka import Producer\n",
        "import json\n",
        "import time\n",
        "\n",
        "config = {\n",
        "\"bootstrap.servers\":\"pkc-619z3.us-east1.gcp.confluent.cloud:9092\",\n",
        "\"security.protocol\":\"SASL_SSL\",\n",
        "\"sasl.mechanisms\":\"PLAIN\",\n",
        "\"sasl.username\":\"7K4SVPMLQXL5AL3A\",\n",
        "\"sasl.password\":\"5XTw3jiNzKiLQLmv0nAmqbQvwgQS/BKD1yF9NchOWAZrj6NrPtMsz5LoZ7DPZ9Vt\",\n",
        "\"session.timeout.ms\":45000,\n",
        "\"client.id\":\"ccloud-python-client-b18b45dd-cd5b-4861-83c8-efe5f5b48977\"\n",
        "}\n",
        "\n",
        "producer = Producer(config)"
      ],
      "metadata": {
        "id": "VT-dmdEpk5cy"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topic = 'topic_0'\n",
        "\n",
        "with open ('customer.json') as f:\n",
        "  customers = json.load(f)"
      ],
      "metadata": {
        "id": "wwc6YyQdk5fK"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "value = customers[0]\n",
        "key = value['customer_id']\n",
        "\n",
        "print (key,value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bg3MFerwq36q",
        "outputId": "65881204-27c9-4bd2-e72d-18e32913239f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 {'customer_id': 0, 'name': 'Customer_0', 'city': 'Pune', 'state': 'Maharashtra', 'country': 'India', 'registration_date': '2023-06-29', 'is_active': False}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(str(value).encode('utf-8'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqwZWZXXq38x",
        "outputId": "f052ed4d-52c7-4a8b-daf4-15f37afc084a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "bytes"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "producer.produce(topic,key=str(key).encode('utf-8'),value=str(value).encode('utf-8'))"
      ],
      "metadata": {
        "id": "5TQR7l08q3-0"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sending multiple data to kafka"
      ],
      "metadata": {
        "id": "y9izY5zSq4A4"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def delivery_status(errs,msg):\n",
        "  if errs:\n",
        "    print(f\"Message delivery failed with error: {errs}\")\n",
        "  else:\n",
        "    print(f\"Message delivered successfully to topic: {msg.topic()} [{msg.partition()}] at offset: {msg.offset()}\")\n",
        "\n",
        "\n",
        "for record in customers:\n",
        "  try:\n",
        "    message_value = json.dumps(record)\n",
        "    message_key = str(record['customer_id']).encode('utf-8')\n",
        "    producer.produce(topic=topic,key=message_key,value=message_value,callback = delivery_status)\n",
        "    producer.poll(1)\n",
        "  except Exception as e:\n",
        "    print (f\"Error happened with : {e}\")\n",
        "\n",
        "producer.flush()\n",
        "print(\"Message sent to kafka\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GmEm4F4q4DO",
        "outputId": "be9cd447-a532-4389-e477-8d7310b0300b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Message delivered successfully to topic: topic_0 [2] at offset: 2\n",
            "Message delivered successfully to topic: topic_0 [2] at offset: 3\n",
            "Message delivered successfully to topic: topic_0 [1] at offset: 0\n",
            "Message delivered successfully to topic: topic_0 [1] at offset: 1\n",
            "Message delivered successfully to topic: topic_0 [1] at offset: 2\n",
            "Message delivered successfully to topic: topic_0 [1] at offset: 3\n",
            "Message delivered successfully to topic: topic_0 [1] at offset: 4\n",
            "Message delivered successfully to topic: topic_0 [0] at offset: 0\n",
            "Message delivered successfully to topic: topic_0 [2] at offset: 4\n",
            "Message delivered successfully to topic: topic_0 [0] at offset: 1\n",
            "Message delivered successfully to topic: topic_0 [0] at offset: 2\n",
            "Message delivered successfully to topic: topic_0 [0] at offset: 3\n",
            "Message delivered successfully to topic: topic_0 [0] at offset: 4\n",
            "Message delivered successfully to topic: topic_0 [2] at offset: 5\n",
            "Message delivered successfully to topic: topic_0 [0] at offset: 5\n",
            "Message delivered successfully to topic: topic_0 [1] at offset: 5\n",
            "Message delivered successfully to topic: topic_0 [0] at offset: 6\n",
            "Message delivered successfully to topic: topic_0 [2] at offset: 6\n",
            "Message delivered successfully to topic: topic_0 [0] at offset: 7\n",
            "Message delivered successfully to topic: topic_0 [1] at offset: 6\n",
            "Message delivered successfully to topic: topic_0 [0] at offset: 8\n",
            "Message delivered successfully to topic: topic_0 [1] at offset: 7\n",
            "Message delivered successfully to topic: topic_0 [2] at offset: 7\n",
            "Message delivered successfully to topic: topic_0 [1] at offset: 8\n",
            "Message delivered successfully to topic: topic_0 [2] at offset: 8\n",
            "Message delivered successfully to topic: topic_0 [0] at offset: 9\n",
            "Message delivered successfully to topic: topic_0 [1] at offset: 9\n",
            "Message delivered successfully to topic: topic_0 [0] at offset: 10\n",
            "Message delivered successfully to topic: topic_0 [0] at offset: 11\n",
            "Message delivered successfully to topic: topic_0 [2] at offset: 9\n",
            "Message delivered successfully to topic: topic_0 [1] at offset: 10\n",
            "Message delivered successfully to topic: topic_0 [1] at offset: 11\n",
            "Message delivered successfully to topic: topic_0 [1] at offset: 12\n",
            "Message delivered successfully to topic: topic_0 [2] at offset: 10\n",
            "Message delivered successfully to topic: topic_0 [2] at offset: 11\n",
            "Message delivered successfully to topic: topic_0 [1] at offset: 13\n",
            "Message delivered successfully to topic: topic_0 [1] at offset: 14\n",
            "Message delivered successfully to topic: topic_0 [1] at offset: 15\n",
            "Message delivered successfully to topic: topic_0 [0] at offset: 12\n",
            "Message delivered successfully to topic: topic_0 [1] at offset: 16\n",
            "Message delivered successfully to topic: topic_0 [2] at offset: 12\n",
            "Message delivered successfully to topic: topic_0 [2] at offset: 13\n",
            "Message delivered successfully to topic: topic_0 [2] at offset: 14\n",
            "Message delivered successfully to topic: topic_0 [1] at offset: 17\n",
            "Message delivered successfully to topic: topic_0 [2] at offset: 15\n",
            "Message delivered successfully to topic: topic_0 [1] at offset: 18\n",
            "Message delivered successfully to topic: topic_0 [0] at offset: 13\n",
            "Message delivered successfully to topic: topic_0 [0] at offset: 14\n",
            "Message delivered successfully to topic: topic_0 [0] at offset: 15\n",
            "Message delivered successfully to topic: topic_0 [0] at offset: 16\n",
            "Message delivered successfully to topic: topic_0 [0] at offset: 17\n",
            "Message delivered successfully to topic: topic_0 [0] at offset: 18\n",
            "Message delivered successfully to topic: topic_0 [1] at offset: 19\n",
            "Message delivered successfully to topic: topic_0 [0] at offset: 19\n",
            "Message delivered successfully to topic: topic_0 [1] at offset: 20\n",
            "Message delivered successfully to topic: topic_0 [2] at offset: 16\n",
            "Message delivered successfully to topic: topic_0 [1] at offset: 21\n",
            "Message delivered successfully to topic: topic_0 [0] at offset: 20\n",
            "Message delivered successfully to topic: topic_0 [0] at offset: 21\n",
            "Message delivered successfully to topic: topic_0 [2] at offset: 17\n",
            "Message delivered successfully to topic: topic_0 [0] at offset: 22\n",
            "Message delivered successfully to topic: topic_0 [1] at offset: 22\n",
            "Message delivered successfully to topic: topic_0 [1] at offset: 23\n",
            "Message delivered successfully to topic: topic_0 [0] at offset: 23\n",
            "Message delivered successfully to topic: topic_0 [0] at offset: 24\n",
            "Message delivered successfully to topic: topic_0 [0] at offset: 25\n",
            "Message delivered successfully to topic: topic_0 [1] at offset: 24\n",
            "Message delivered successfully to topic: topic_0 [1] at offset: 25\n",
            "Message delivered successfully to topic: topic_0 [1] at offset: 26\n",
            "Message delivered successfully to topic: topic_0 [1] at offset: 27\n",
            "Message delivered successfully to topic: topic_0 [1] at offset: 28\n",
            "Message delivered successfully to topic: topic_0 [1] at offset: 29\n",
            "Message delivered successfully to topic: topic_0 [0] at offset: 26\n",
            "Message delivered successfully to topic: topic_0 [1] at offset: 30\n",
            "Message delivered successfully to topic: topic_0 [2] at offset: 18\n",
            "Message delivered successfully to topic: topic_0 [0] at offset: 27\n",
            "Message delivered successfully to topic: topic_0 [2] at offset: 19\n",
            "Message delivered successfully to topic: topic_0 [0] at offset: 28\n",
            "Message delivered successfully to topic: topic_0 [0] at offset: 29\n",
            "Message delivered successfully to topic: topic_0 [2] at offset: 20\n",
            "Message delivered successfully to topic: topic_0 [0] at offset: 30\n",
            "Message delivered successfully to topic: topic_0 [2] at offset: 21\n",
            "Message delivered successfully to topic: topic_0 [0] at offset: 31\n",
            "Message delivered successfully to topic: topic_0 [2] at offset: 22\n",
            "Message delivered successfully to topic: topic_0 [1] at offset: 31\n",
            "Message delivered successfully to topic: topic_0 [0] at offset: 32\n",
            "Message delivered successfully to topic: topic_0 [0] at offset: 33\n",
            "Message delivered successfully to topic: topic_0 [1] at offset: 32\n",
            "Message delivered successfully to topic: topic_0 [1] at offset: 33\n",
            "Message delivered successfully to topic: topic_0 [0] at offset: 34\n",
            "Message delivered successfully to topic: topic_0 [0] at offset: 35\n",
            "Message delivered successfully to topic: topic_0 [0] at offset: 36\n",
            "Message delivered successfully to topic: topic_0 [1] at offset: 34\n",
            "Message delivered successfully to topic: topic_0 [1] at offset: 35\n",
            "Message delivered successfully to topic: topic_0 [0] at offset: 37\n",
            "Message delivered successfully to topic: topic_0 [0] at offset: 38\n",
            "Message delivered successfully to topic: topic_0 [1] at offset: 36\n",
            "Message delivered successfully to topic: topic_0 [0] at offset: 39\n",
            "Message delivered successfully to topic: topic_0 [0] at offset: 40\n",
            "Message sent to kafka\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S7YnwgFBq4FF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RZDoR5U-q4Hi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}